{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main advantages of Hierarchical CLustering:\n",
    "- Do not have to assume any particular number of clusters, any desired number of clusters can be obtained cuttin the endogram\n",
    "- They may correspond to meaningful taxonomies: gerarchical classification of objects\n",
    "\n",
    "## Two main types\n",
    "1) Agglomerative: start with each poin as indivudual clustes and merge clustest while we have k clusters\n",
    "2) Divisive: start with all-inclusive cluster and split while we have k clustes\n",
    "\n",
    "In both cases we have to choose a distance measure and split/merge one cluster at a time, selecting the two clusters that have the minumum distance\n",
    "\n",
    "## Inter-Cluster Distane\n",
    "- MIN (single link): closest points in the two clusters\n",
    "    - take strongly into account the contiguity so it can handle globular shapes but it is sentitive to noise\n",
    "- MAX (complete link): farther points in the two clusters\n",
    "    - less subsceptible to noise but tends to break large clusters and is biased towards globular ones\n",
    "- Group average: mean of all possible distances between the point of the two clusters\n",
    "    - good compromise between single and complete link, still a bit biased toward globular clusters\n",
    "- Distance between centroids: distance between the centroids of the two clusters\n",
    "- Ward's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/users_df_dataset_cleaned_with_indicators.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>bot</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>account_age_in_days</th>\n",
       "      <th>number_of_tweets</th>\n",
       "      <th>account_average_tweets_per_day</th>\n",
       "      <th>avg_tweets_per_actual_day</th>\n",
       "      <th>max_number_of_tweet_in_a_day</th>\n",
       "      <th>entropy_for_day</th>\n",
       "      <th>entropy_for_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_mentions</th>\n",
       "      <th>avg_special_char_in_text</th>\n",
       "      <th>total_likes</th>\n",
       "      <th>avt_favorite_count</th>\n",
       "      <th>total_replies</th>\n",
       "      <th>avt_reply_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>account_discussion_creation_ratio</th>\n",
       "      <th>tweet_num_likes_ratio</th>\n",
       "      <th>tweet_num_replies_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.110900e+04</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>1.110900e+04</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>1.110900e+04</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>1.110900e+04</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "      <td>11109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.263638e+09</td>\n",
       "      <td>0.550545</td>\n",
       "      <td>486.128364</td>\n",
       "      <td>1827.599874</td>\n",
       "      <td>941.636241</td>\n",
       "      <td>0.262958</td>\n",
       "      <td>13.376648</td>\n",
       "      <td>52.172383</td>\n",
       "      <td>2.795355</td>\n",
       "      <td>1.995941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366564</td>\n",
       "      <td>15.984273</td>\n",
       "      <td>3.207103e+03</td>\n",
       "      <td>17.719387</td>\n",
       "      <td>9.356540e+02</td>\n",
       "      <td>0.603060</td>\n",
       "      <td>5.264295e+05</td>\n",
       "      <td>19.514334</td>\n",
       "      <td>17.394735</td>\n",
       "      <td>4.133898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.362909e+08</td>\n",
       "      <td>0.497461</td>\n",
       "      <td>1240.441286</td>\n",
       "      <td>555.089451</td>\n",
       "      <td>1199.366972</td>\n",
       "      <td>0.680883</td>\n",
       "      <td>37.977049</td>\n",
       "      <td>87.943561</td>\n",
       "      <td>1.460038</td>\n",
       "      <td>1.086827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372468</td>\n",
       "      <td>5.572540</td>\n",
       "      <td>9.749422e+04</td>\n",
       "      <td>335.748836</td>\n",
       "      <td>2.983748e+04</td>\n",
       "      <td>12.405792</td>\n",
       "      <td>2.931097e+06</td>\n",
       "      <td>80.962879</td>\n",
       "      <td>46.416587</td>\n",
       "      <td>29.053336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.780330e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.662898e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.426345</td>\n",
       "      <td>1.032784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>13.640127</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.957981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.127892e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1702.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.921107</td>\n",
       "      <td>2.234517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318584</td>\n",
       "      <td>15.175325</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>0.040902</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.356956e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>2080.000000</td>\n",
       "      <td>1703.000000</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>8.058511</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.710199</td>\n",
       "      <td>2.789275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553221</td>\n",
       "      <td>17.797753</td>\n",
       "      <td>3.900000e+02</td>\n",
       "      <td>0.267796</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.473700e+04</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.164942e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7226.000000</td>\n",
       "      <td>3901.000000</td>\n",
       "      <td>3668.000000</td>\n",
       "      <td>6.792821</td>\n",
       "      <td>1759.500000</td>\n",
       "      <td>2131.000000</td>\n",
       "      <td>5.706424</td>\n",
       "      <td>5.705947</td>\n",
       "      <td>...</td>\n",
       "      <td>5.701754</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>7.006348e+06</td>\n",
       "      <td>13542.800000</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>603.318250</td>\n",
       "      <td>9.638758e+07</td>\n",
       "      <td>3519.000000</td>\n",
       "      <td>2877.000000</td>\n",
       "      <td>1762.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id           bot  statuses_count  account_age_in_days  \\\n",
       "count  1.110900e+04  11109.000000    11109.000000         11109.000000   \n",
       "mean   1.263638e+09      0.550545      486.128364          1827.599874   \n",
       "std    9.362909e+08      0.497461     1240.441286           555.089451   \n",
       "min    6.780330e+05      0.000000        0.000000           891.000000   \n",
       "25%    4.662898e+08      0.000000       41.000000          1312.000000   \n",
       "50%    1.127892e+09      1.000000       68.000000          1702.000000   \n",
       "75%    2.356956e+09      1.000000       81.000000          2080.000000   \n",
       "max    3.164942e+09      1.000000     7226.000000          3901.000000   \n",
       "\n",
       "       number_of_tweets  account_average_tweets_per_day  \\\n",
       "count      11109.000000                    11109.000000   \n",
       "mean         941.636241                        0.262958   \n",
       "std         1199.366972                        0.680883   \n",
       "min            1.000000                        0.000000   \n",
       "25%           67.000000                        0.022472   \n",
       "50%          132.000000                        0.035088   \n",
       "75%         1703.000000                        0.058267   \n",
       "max         3668.000000                        6.792821   \n",
       "\n",
       "       avg_tweets_per_actual_day  max_number_of_tweet_in_a_day  \\\n",
       "count               11109.000000                  11109.000000   \n",
       "mean                   13.376648                     52.172383   \n",
       "std                    37.977049                     87.943561   \n",
       "min                     1.000000                      1.000000   \n",
       "25%                     1.846154                      6.000000   \n",
       "50%                     4.777778                     18.000000   \n",
       "75%                     8.058511                     75.000000   \n",
       "max                  1759.500000                   2131.000000   \n",
       "\n",
       "       entropy_for_day  entropy_for_hour  ...  avg_mentions  \\\n",
       "count     11109.000000      11109.000000  ...  11109.000000   \n",
       "mean          2.795355          1.995941  ...      0.366564   \n",
       "std           1.460038          1.086827  ...      0.372468   \n",
       "min           0.000000          0.000000  ...      0.000000   \n",
       "25%           1.426345          1.032784  ...      0.010862   \n",
       "50%           2.921107          2.234517  ...      0.318584   \n",
       "75%           3.710199          2.789275  ...      0.553221   \n",
       "max           5.706424          5.705947  ...      5.701754   \n",
       "\n",
       "       avg_special_char_in_text   total_likes  avt_favorite_count  \\\n",
       "count              11109.000000  1.110900e+04        11109.000000   \n",
       "mean                  15.984273  3.207103e+03           17.719387   \n",
       "std                    5.572540  9.749422e+04          335.748836   \n",
       "min                    0.000000  0.000000e+00            0.000000   \n",
       "25%                   13.640127  3.000000e+00            0.023837   \n",
       "50%                   15.175325  1.000000e+01            0.064815   \n",
       "75%                   17.797753  3.900000e+02            0.267796   \n",
       "max                  149.000000  7.006348e+06        13542.800000   \n",
       "\n",
       "       total_replies  avt_reply_count  total_retweet_count  \\\n",
       "count   1.110900e+04     11109.000000         1.110900e+04   \n",
       "mean    9.356540e+02         0.603060         5.264295e+05   \n",
       "std     2.983748e+04        12.405792         2.931097e+06   \n",
       "min     0.000000e+00         0.000000         0.000000e+00   \n",
       "25%     0.000000e+00         0.000000         3.000000e+00   \n",
       "50%     0.000000e+00         0.000000         7.700000e+01   \n",
       "75%     0.000000e+00         0.000000         6.473700e+04   \n",
       "max     2.000000e+06       603.318250         9.638758e+07   \n",
       "\n",
       "       account_discussion_creation_ratio  tweet_num_likes_ratio  \\\n",
       "count                       11109.000000           11109.000000   \n",
       "mean                           19.514334              17.394735   \n",
       "std                            80.962879              46.416587   \n",
       "min                             0.000000               0.000000   \n",
       "25%                             0.001644               0.957981   \n",
       "50%                             0.040902               7.500000   \n",
       "75%                            20.000000              20.800000   \n",
       "max                          3519.000000            2877.000000   \n",
       "\n",
       "       tweet_num_replies_ratio  \n",
       "count             11109.000000  \n",
       "mean                  4.133898  \n",
       "std                  29.053336  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                1762.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, since we will work on numerical features we remove categorical/nominal? attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"user_id\", \"name\", \"lang\", \"bot\", \"created_at\", \"day_with_most_tweets\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to normalize the attributes to avoid bias given by the different range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "transformed_array = scaler.fit_transform(df.values)\n",
    "#numpy array of array, each array rappresent a row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairwise distances between observations in n-dimensional space.\n",
    "data_dist = pdist(transformed_array, metric='euclidean')\n",
    "# Perform hierarchical/agglomerative clustering.    \n",
    "data_link = linkage(data_dist, method='complete', metric='euclidean')\n",
    "# Plot the hierarchical clustering as a dendrogram.\n",
    "# res = dendrogram(data_link, color_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying with %d clusters 2\n",
      "trying with %d clusters 3\n"
     ]
    }
   ],
   "source": [
    "max_clusters = 20 #max number of clusters to try\n",
    "\n",
    "for num_curr_clusters in range(2, max_clusters):\n",
    "    labels = AgglomerativeClustering(n_clusters=num_curr_clusters, affinity='euclidean', linkage='ward').fit_predict(df)\n",
    "    print(\"trying with\", num_curr_clusters, \"clusters\")\n",
    "\n",
    "    cluster_map = {\n",
    "        cluster_index : list_of_points\n",
    "        for \n",
    "    }\n",
    "\n",
    "    for cluster in range(num_curr_clusters):\n",
    "        centroid = \"calculate centroid\"\n",
    "        for point in cluster:\n",
    "            SSE[cluster] += np.norm(np.sub(point, centroid))\n",
    "            \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
