{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run this you have to update your merged dataset with the one without the null text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import lingua_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "import os\n",
    "import lingua_utils as lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'concurrent_language_model.<locals>.process_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m tweet_df[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tweet_df[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m# casting all elements to string\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tweets_df \u001b[39m=\u001b[39m tweet_df[\u001b[39m~\u001b[39mtweet_df\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39misspace()] \u001b[39m# dropping tweets with only spaces\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m tweets_lang_df \u001b[39m=\u001b[39m lu\u001b[39m.\u001b[39mconcurrent_language_model(tweet_df, parallelism_level)\n\u001b[0;32m     14\u001b[0m tweets_lang_df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m./dataset/tweets_lang.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Scripts\\bots_on_twitter\\lingua_utils.py:29\u001b[0m, in \u001b[0;36mconcurrent_language_model\u001b[1;34m(dataset, parallelism_level)\u001b[0m\n\u001b[0;32m     26\u001b[0m \tprocess_list\u001b[39m.\u001b[39mappend(mp\u001b[39m.\u001b[39mProcess(target\u001b[39m=\u001b[39mprocess_function, args\u001b[39m=\u001b[39m( i, splitted_dataset[i] , concurrent_queue,  )))\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m process_list:\n\u001b[1;32m---> 29\u001b[0m \ti\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m     31\u001b[0m splitted_dataset \u001b[39m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll\u001b[39m\u001b[39m\"\u001b[39m, num_process, \u001b[39m\"\u001b[39m\u001b[39mprocesses runnig ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'concurrent_language_model.<locals>.process_function'"
     ]
    }
   ],
   "source": [
    "parallelism_level = 12\n",
    "path = \"./dataset/merged_dataset_cleaned.csv\"\n",
    "\n",
    "if (os.path.exists(path)):\n",
    "    tweets_lang_df = pd.read_csv(path)\n",
    "else:\n",
    "    tweet_df = pd.read_csv(\"dataset/tweets.csv\")\n",
    "    tweet_df.drop(labels=[\"user_id\", \"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\", \"created_at\"], axis=1, inplace=True) # dropping all the columns except tweet_id and text \n",
    "    tweet_df.rename(columns={\"id\" : \"tweet_id\"}, inplace=True)\n",
    "    tweet_df.dropna(subset=[\"text\"], inplace=True) # dropping nan text fields\n",
    "    tweet_df[\"text\"] = tweet_df[\"text\"].astype(str) # casting all elements to string\n",
    "    tweets_df = tweet_df[~tweet_df.text.str.isspace()] # dropping tweets with only spaces\n",
    "\n",
    "    tweets_lang_df = lu.concurrent_language_model(tweet_df, parallelism_level)\n",
    "    tweets_lang_df.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
