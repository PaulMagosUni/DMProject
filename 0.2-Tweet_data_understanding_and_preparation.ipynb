{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\")\n",
    "users_df = pd.read_csv(\"dataset/users_dataset_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Data Understanding and Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tweets.csv each row contains information about a single tweet. There are 10 columns and In this case the variables are:\n",
    "\n",
    "1. ID: a unique identifier for the tweet\n",
    "\n",
    "2. User Id: a unique identifier for the user who wrote the tweet\n",
    "\n",
    "3. Retweet count: number of retweets for the tweet in analysis\n",
    "\n",
    "4. Reply count: number of reply for the tweet in analysis\n",
    "\n",
    "5. Favorite count: number of favorites (likes) received by the tweet\n",
    "\n",
    "6. Num hashtags: number of hashtags used in the tweet\n",
    "\n",
    "7. Num urls: number of urls in the tweet\n",
    "\n",
    "8. Num mentions: number of mentions in the tweet\n",
    "\n",
    "9. Created at: when the tweet was created\n",
    "\n",
    "10. Text: the text of the tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute type and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count     Dtype \n",
      "---  ------          --------------     ----- \n",
      " 0   id              13664694 non-null  object\n",
      " 1   user_id         13447413 non-null  object\n",
      " 2   retweet_count   13227562 non-null  object\n",
      " 3   reply_count     13016818 non-null  object\n",
      " 4   favorite_count  13017154 non-null  object\n",
      " 5   num_hashtags    12607172 non-null  object\n",
      " 6   num_urls        13016073 non-null  object\n",
      " 7   num_mentions    12810531 non-null  object\n",
      " 8   created_at      13664696 non-null  object\n",
      " 9   text            13126975 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 8.9 GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tweet_id & User_id Columns\n",
    "\n",
    "keeping only the tweets with user_id in user dataset. As these are the ones we would like to study, and have the data to verify the validity of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.rename(columns= {\"id\" : \"tweet_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tweets whose author id isn't inside the users dataframe: 3.56021092602426\n"
     ]
    }
   ],
   "source": [
    "before_dropping_rows_number = len(tweets_df.index)\n",
    "\n",
    "numeric_ids = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "ids_are_not_in_users_df = numeric_ids[numeric_ids.isin(users_df[\"user_id\"]) == False]\n",
    "tweets_df.drop(ids_are_not_in_users_df.index, inplace=True)\n",
    "\n",
    "tweets_df[\"user_id\"] = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "\n",
    "after_dropping_rows_number = len(tweets_df.index)\n",
    "\n",
    "print(f\"Percentage of tweets whose author id isn't inside the users dataframe: {(100*(before_dropping_rows_number-after_dropping_rows_number))/(before_dropping_rows_number)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tweets are dropped from the tweets dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by casting to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"tweet_id\"] = pd.to_numeric(tweets_df[\"tweet_id\"], errors=\"coerce\") # cast field to int and set invalid values to NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing tweets which are duplicates on every attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tweets duplicated along all the columns that we are deleting(after keeping the first instance): 14.75545529572922\n"
     ]
    }
   ],
   "source": [
    "original_number_rows = len(tweets_df.index)\n",
    "\n",
    "all_columns_duplicated_df = tweets_df[tweets_df.duplicated(subset=None, keep=\"first\")]\n",
    "all_columns_duplicated_number = len(all_columns_duplicated_df.index)\n",
    "\n",
    "print(f\"Percentage of tweets duplicated along all the columns that we are deleting(after keeping the first instance): {(100*(all_columns_duplicated_number))/original_number_rows}\")\n",
    "\n",
    "tweets_df.drop(labels=all_columns_duplicated_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping tweets whose id is an invalid value (i.e. NaN, duplicate, inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tweets with nan tweet_id dropped: 3.333923818510375\n"
     ]
    }
   ],
   "source": [
    "before = tweets_df.size\n",
    "tweets_df = tweets_df[tweets_df['tweet_id'].notna()]\n",
    "after= tweets_df.size\n",
    "print(f\"Percentage of tweets with nan tweet_id dropped: {(100*(before - after))/before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of tweets with same tweet_id dropped: 5480\n"
     ]
    }
   ],
   "source": [
    "before = tweets_df.size\n",
    "tweets_df = tweets_df.drop_duplicates(subset=\"tweet_id\")\n",
    "after = tweets_df.size\n",
    "print(f\"Num of tweets with same tweet_id dropped: {(before - after)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of tweets with inf tweet_id dropped: 10\n"
     ]
    }
   ],
   "source": [
    "before = tweets_df.size\n",
    "tweets_df = tweets_df[tweets_df['tweet_id']!=np.inf]\n",
    "after = tweets_df.size\n",
    "print(f\"Num of tweets with inf tweet_id dropped: {(before - after)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to drop all tweets with NaN values as their ID. As it is difficult for us to ensure their validity. We have also decided to drop all tweets with duplicated IDs. Keeping only its first instance. \n",
    "\n",
    "As we can see from the data above. Pandas treats tweets with fields containing NaN values as different from each other. Atleast when it comes to ID. \n",
    "\n",
    "Lets see if we can find the tweets with non-NaN user-id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of tweets with nan user_id dropped: 0.0\n"
     ]
    }
   ],
   "source": [
    "before = tweets_df.size\n",
    "tweets_df = tweets_df[tweets_df['user_id'].notna()]\n",
    "after= tweets_df.size\n",
    "print(f\"Percentage of tweets with nan user_id dropped: {(100*(before - after))/before}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert tweet_id attribute to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10858628 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   tweet_id        int64 \n",
      " 1   user_id         int64 \n",
      " 2   retweet_count   object\n",
      " 3   reply_count     object\n",
      " 4   favorite_count  object\n",
      " 5   num_hashtags    object\n",
      " 6   num_urls        object\n",
      " 7   num_mentions    object\n",
      " 8   created_at      object\n",
      " 9   text            object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 911.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df[\"tweet_id\"] = tweets_df[\"tweet_id\"].astype(np.int64)\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numerical columns\n",
    "\n",
    "- Retweet_count\n",
    "- Reply_count\n",
    "- favorite_count\n",
    "- Num_hashtags\n",
    "- Num_urls\n",
    "- num_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10589137</td>\n",
       "      <td>10480176</td>\n",
       "      <td>10479682</td>\n",
       "      <td>10259406</td>\n",
       "      <td>10479097</td>\n",
       "      <td>10369957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>181213</td>\n",
       "      <td>117598</td>\n",
       "      <td>117707</td>\n",
       "      <td>77700</td>\n",
       "      <td>116554</td>\n",
       "      <td>97775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7540373</td>\n",
       "      <td>9803698</td>\n",
       "      <td>7866508</td>\n",
       "      <td>8704828</td>\n",
       "      <td>8223780</td>\n",
       "      <td>6116212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       retweet_count reply_count favorite_count num_hashtags  num_urls  \\\n",
       "count       10589137    10480176       10479682     10259406  10479097   \n",
       "unique        181213      117598         117707        77700    116554   \n",
       "top                0           0              0            0         0   \n",
       "freq         7540373     9803698        7866508      8704828   8223780   \n",
       "\n",
       "       num_mentions  \n",
       "count      10369957  \n",
       "unique        97775  \n",
       "top               0  \n",
       "freq        6116212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "tweets_df[columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following thresholds are based on the most retweet and \"liked\" tweets on the twitter platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid values for the following columns:\n",
      "retweet_count\n",
      "\tnegative: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17130/414869727.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df[column_name].loc[negative_series.index] = np.NaN # setting negative values to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinf: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17130/414869727.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df[column_name].loc[inf_series.index] = np.NaN # setting inf values to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdecimals: 0\n",
      "\tvalues above threshold (3738380): 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17130/414869727.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_df[column_name].loc[above_threshold_series.index] = np.NaN # setting values above threshold to nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply_count\n",
      "\tnegative: 0\n",
      "\tinf: 1\n",
      "\tdecimals: 0\n",
      "favorite_count\n",
      "\tnegative: 1\n",
      "\tinf: 0\n",
      "\tdecimals: 0\n",
      "\tvalues above threshold (7114892): 34\n",
      "num_hashtags\n",
      "\tnegative: 0\n",
      "\tinf: 0\n",
      "\tdecimals: 0\n",
      "num_urls\n",
      "\tnegative: 0\n",
      "\tinf: 0\n",
      "\tdecimals: 0\n",
      "num_mentions\n",
      "\tnegative: 0\n",
      "\tinf: 0\n",
      "\tdecimals: 0\n"
     ]
    }
   ],
   "source": [
    "thresholds = {\n",
    "   \"retweet_count\": 3738380,\n",
    "   \"favorite_count\": 7114892\n",
    "}\n",
    "\n",
    "print(\"Number of invalid values for the following columns:\")\n",
    "for column_name in columns:\n",
    "   # casting all the columns to numeric (and setting invalid value to null)\n",
    "   tweets_df[column_name] = pd.to_numeric(tweets_df[column_name], errors=\"coerce\")\n",
    "\n",
    "   print(f\"{column_name}\")\n",
    "   # evaluating the presence of negative values\n",
    "   negative_series = tweets_df[tweets_df[column_name] < 0][column_name]\n",
    "   print(f\"\\tnegative: {negative_series.size}\")\n",
    "   tweets_df[column_name].loc[negative_series.index] = np.NaN # setting negative values to NaN\n",
    "   \n",
    "   # evaluating the presence of inf values\n",
    "   inf_series = utils.get_inf_elements(tweets_df[column_name])\n",
    "   print(f\"\\tinf: {inf_series.size}\")\n",
    "   tweets_df[column_name].loc[inf_series.index] = np.NaN # setting inf values to NaN\n",
    "\n",
    "   # evaluating the presence of decimal values\n",
    "   is_float = lambda n: (not pd.isna(n)) and (not math.isinf(n)) and (not n.is_integer())\n",
    "   decimal_values_series =  tweets_df[column_name].apply(is_float)\n",
    "   print(f\"\\tdecimals: {tweets_df[column_name][decimal_values_series].size}\")\n",
    "   \n",
    "   # finding values above given thresholds (if specified)\n",
    "   if column_name in thresholds:\n",
    "       threshold = thresholds[column_name]\n",
    "       above_threshold_series = tweets_df[tweets_df[column_name] > threshold ][column_name]\n",
    "       print(f\"\\tvalues above threshold ({threshold}): {above_threshold_series[above_threshold_series > threshold].size}\") \n",
    "       tweets_df[column_name].loc[above_threshold_series.index] = np.NaN # setting values above threshold to nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observation that can be made is that \\*_count and num_\\* fields should contain only positive integers. Something that they do.\n",
    "We find some inf values in the following columns:\n",
    "- retweet_count\n",
    "- reply_count\n",
    "\n",
    "We also find values that are above our treshold range: \n",
    "- 36 tweets above the retweet_count treshold\n",
    "- 34 tweets above the favorite_count treshold\n",
    "\n",
    "\n",
    "All these values and the infinate values are set to NaN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing columns to integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituting NaN values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    column_median_value = tweets_df[column].median()\n",
    "    tweets_df[column] = tweets_df[column].fillna(column_median_value)\n",
    "    # parsing column type to int\n",
    "    tweets_df[column] = tweets_df[column].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Created_at Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created_at should be datetime\n",
    "\n",
    "Checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"created_at\"] = pd.to_datetime(tweets_df[\"created_at\"], errors=\"coerce\")\n",
    "\n",
    "# finding tweets created before twitter first tweet\n",
    "before_time_tweets_df = tweets_df[tweets_df[\"created_at\"] < datetime(2006,3,21,12,50,0)]\n",
    "before_time_tweets_df.info()\n",
    "\n",
    "# finding tweets created after dataset release\n",
    "before_time_tweets_df = tweets_df[tweets_df[\"created_at\"] > datetime(2022,9,29,11,0,0)]\n",
    "before_time_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()\n",
    "tweets_df = tweets_df[tweets_df[\"created_at\"] > datetime(2006,3,21,12,50,0)]\n",
    "\n",
    "# finding tweets created after dataset release\n",
    "tweets_df = tweets_df[tweets_df[\"created_at\"] < datetime(2022,9,29,11,0,0)]\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") \n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing tweets with null text field, float text field or only spaces, because these are not allowed by twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.dropna(subset=[\"text\"], inplace=True) # drop the tweets where the text field is null\n",
    "tweets_df[\"text\"] = tweets_df[\"text\"].astype(str) # cast the text field to string\n",
    "tweets_df = tweets_df[~tweets_df.text.str.isspace()]\n",
    "\n",
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") \n",
    "tweets_df.describe()\n",
    "# Problem with memory usage, we have to find a more effient way to remove tweets with only spaces\n",
    "# We should also drop the tweets only containing the U+3164 HANGUL FILLER, or other invisible charackters.\n",
    "#Source: https://invisible-characters.com/\n",
    "\"\"\"\n",
    "to_drop = []\n",
    "for index, row in tweets_df.iterrows():\n",
    "    if row[\"text\"].isspace():\n",
    "        tweets_df.drop(index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!\n",
    "\n",
    "Histograms for numerical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# REPLACING INF TO NAN; THIS IS JUST A TEMPORARY FUNCTION I PUT HERE IN ORDER TO PLOT THE HISTOGRAMS - Gianluca\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "####\n",
    "tweets_df.hist(\n",
    "    column=columns, \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(tweets_df.size)\n",
    ")\n",
    "\"\"\"\n",
    "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "\n",
    "tweets_df.hist(\n",
    "    column=columns, \n",
    "    log=True,\n",
    "    #bins=utils.get_sturges_bins(tweets_df.size)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots for the numerical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    tweets_df.plot(kind=\"box\",\n",
    "        column=column,\n",
    "        logy=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the boxplots we can see that there is a very high variance for the data (an observation supported also by the previous histograms). Hence, we compute the whiskers upper and lower bounds analitically for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection\n",
    "outlier_thresholds = {\n",
    "    column: utils.compute_whiskers(tweets_df[column])\n",
    "    for column in columns\n",
    "}\n",
    "\n",
    "outlier_dataframes = {\n",
    "    column: tweets_df[tweets_df[column] > outlier_thresholds[column][1]][column]\n",
    "    for column in columns\n",
    "}\n",
    "\n",
    "for column in columns:\n",
    "    print(f\"{column}: {len(outlier_dataframes[column])} outliers\")\n",
    "\n",
    "# Should add what percentage of the dataframe that this consists of.\n",
    "# In this way we get a feeling of how many outliers our cleaned dataset consists of\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These outliers may be removed from the dataframe by running the code block bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removal of outliers\n",
    "# outlier_indexes_list = [outlier_dataframe.index for outlier_dataframe in outlier_dataframes.values()]\n",
    "# for indexes in outlier_indexes_list:\n",
    "#     tweets_df.drop(indexes, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10858628 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count     Dtype \n",
      "---  ------          --------------     ----- \n",
      " 0   tweet_id        10858628 non-null  int64 \n",
      " 1   user_id         10858628 non-null  int64 \n",
      " 2   retweet_count   10858628 non-null  int64 \n",
      " 3   reply_count     10858628 non-null  int64 \n",
      " 4   favorite_count  10858628 non-null  int64 \n",
      " 5   num_hashtags    10858628 non-null  int64 \n",
      " 6   num_urls        10858628 non-null  int64 \n",
      " 7   num_mentions    10858628 non-null  int64 \n",
      " 8   created_at      10858628 non-null  object\n",
      " 9   text            10557870 non-null  object\n",
      "dtypes: int64(8), object(2)\n",
      "memory usage: 3.2 GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This codeblock should compute the number of tweets belonging to human and bot accounts\n",
    "# It should also compute the percentage of this data, to come up with a number for balance\n",
    "\n",
    "# We also have to decide if we should remove the remaining tweets that include NaN values.\n",
    "# These are around 400 thousand of our 10 million four hundred thousand remaining tweets.\n",
    "# So basically less than 4%\n",
    "\n",
    "# Number_of_users_in_dataset_that_are_bots = users_df.groupby(\"bot\").get_group(1)\n",
    "# Number_of_users_in_dataset_that_are_humans = users_df.groupby(\"bot\").get_group(0)\n",
    "# total = len(Number_of_users_in_dataset_that_are_bots) + len(Number_of_users_in_dataset_that_are_humans)\n",
    "# print(f\"Out of the {total} users in our dataset. {len(Number_of_users_in_dataset_that_are_humans)} are humans, and {len(Number_of_users_in_dataset_that_are_bots)} are bots.\")\n",
    "# print(f\"The dataset consists of {round(100*(len(Number_of_users_in_dataset_that_are_humans)/total),3)}% humans and {round(100*(len(Number_of_users_in_dataset_that_are_bots)/total),3)}% bots respectively.\")\n",
    "# print(f\"399 of our users are missing their statuses_count values. These humans consist of {round(100*(len(list_of_humans)/total),3)}% of our dataset.\")\n",
    "# print(f\"These users will be removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block should explain the the state of the cleaned and generalized dataset. Also stating how balanced it is.\n",
    "\n",
    "From the users cleaning notebook\n",
    ".......................................\n",
    "After cleaning we are left with a \"fairly\" balanced and generalized dataset, that is ready for further use. The dataset contains approx. 45% human and 55% bot users. \n",
    "......................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"./dataset/tweets_dataset_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
