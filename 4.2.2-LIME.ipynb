{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e721783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "221c0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_filepath = \"models/nn_model\"\n",
    "nn_model = tf.keras.models.load_model(saved_filepath)\n",
    "df = pd.read_csv(\"./dataset/users_df_dataset_cleaned_with_indicators.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dee047b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "#    \"user_id\"  ,\n",
    "#    \"name\"  ,\n",
    "#    \"lang\"  ,\n",
    "    \"bot\"  ,\n",
    "#    \"created_at\" ,\n",
    "    \"statuses_count\" ,\n",
    "    \"account_age_in_days\" ,\n",
    "    \"number_of_tweets\" ,\n",
    "    \"account_average_tweets_per_day\" ,\n",
    "    \"avg_tweets_per_actual_day\" ,\n",
    "#    \"day_with_most_tweets\" ,\n",
    "    \"max_number_of_tweets_in_a_day\",\n",
    "    \"entropy_for_day\",\n",
    "    \"entropy_for_hour\",\n",
    "    \"entropy_for_minute\",\n",
    "    \"avg_hashtags\",\n",
    "    \"avg_text_length\",\n",
    "    \"avg_mentions\",\n",
    "    \"avg_special_char_in_text\",\n",
    "    \"total_likes\",\n",
    "    \"avt_favorite_count\",\n",
    "    \"total_replies\",\n",
    "    \"avt_reply_count\",\n",
    "    \"total_retweet_count\",\n",
    "    \"account_discussion_creation_ratio\",\n",
    "    \"tweet_num_likes_ratio\",\n",
    "    \"tweet_num_replies_ratio\",\n",
    "    \"entropy_original_text\",\n",
    "    \"entropy_text\",\n",
    "    \"mean_inactive_period_length_in_seconds\",\n",
    "    \"median_inactive_period_length_in_seconds\",\n",
    "    \"mode_inactive_period_length_in_seconds\",\n",
    "    \"mode_count\"\n",
    "]]\n",
    "\n",
    "df = df.sample(frac=1, random_state=1).reset_index() #the same random state of the model \n",
    "df.pop(\"bot\")\n",
    "\n",
    "tr_size = 0.7 # the same for the model\n",
    "\n",
    "tr_index = round(df.shape[0] * tr_size)\n",
    "\n",
    "df_train = df[0:tr_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f5991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=df_train.values, \n",
    "    mode=\"classification\",\n",
    "    verbose=True,\n",
    "    class_names=(\"human\", \"bot\"),\n",
    "    sample_around_instance=True , # WARNING don't know if it is good\n",
    "    feature_names = df.columns.tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c27830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 914us/step\n",
      "157/157 [==============================] - 0s 822us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/.local/lib/python3.10/site-packages/lime/lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5000, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m instance_index \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m exp \u001b[39m=\u001b[39m lime_explainer\u001b[39m.\u001b[39;49mexplain_instance(\n\u001b[1;32m      3\u001b[0m     data_row \u001b[39m=\u001b[39;49m df\u001b[39m.\u001b[39;49mvalues[instance_index], \n\u001b[1;32m      4\u001b[0m     predict_fn \u001b[39m=\u001b[39;49m  \u001b[39mlambda\u001b[39;49;00m x: np\u001b[39m.\u001b[39;49marray([nn_model\u001b[39m.\u001b[39;49mpredict(x), \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m nn_model\u001b[39m.\u001b[39;49mpredict(x)])\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), \n\u001b[1;32m      5\u001b[0m     top_labels\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m      6\u001b[0m    )\n\u001b[1;32m      8\u001b[0m exp\u001b[39m.\u001b[39mshow_in_notebook(\n\u001b[1;32m      9\u001b[0m     show_predicted_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     show_table\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     show_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_tabular.py:452\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    448\u001b[0m     labels \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m]\n\u001b[1;32m    449\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels:\n\u001b[1;32m    450\u001b[0m     (ret_exp\u001b[39m.\u001b[39mintercept[label],\n\u001b[1;32m    451\u001b[0m      ret_exp\u001b[39m.\u001b[39mlocal_exp[label],\n\u001b[0;32m--> 452\u001b[0m      ret_exp\u001b[39m.\u001b[39mscore, ret_exp\u001b[39m.\u001b[39mlocal_pred) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase\u001b[39m.\u001b[39;49mexplain_instance_with_data(\n\u001b[1;32m    453\u001b[0m             scaled_data,\n\u001b[1;32m    454\u001b[0m             yss,\n\u001b[1;32m    455\u001b[0m             distances,\n\u001b[1;32m    456\u001b[0m             label,\n\u001b[1;32m    457\u001b[0m             num_features,\n\u001b[1;32m    458\u001b[0m             model_regressor\u001b[39m=\u001b[39;49mmodel_regressor,\n\u001b[1;32m    459\u001b[0m             feature_selection\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_selection)\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     ret_exp\u001b[39m.\u001b[39mintercept[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m ret_exp\u001b[39m.\u001b[39mintercept[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_base.py:183\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    181\u001b[0m weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_fn(distances)\n\u001b[1;32m    182\u001b[0m labels_column \u001b[39m=\u001b[39m neighborhood_labels[:, label]\n\u001b[0;32m--> 183\u001b[0m used_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_selection(neighborhood_data,\n\u001b[1;32m    184\u001b[0m                                        labels_column,\n\u001b[1;32m    185\u001b[0m                                        weights,\n\u001b[1;32m    186\u001b[0m                                        num_features,\n\u001b[1;32m    187\u001b[0m                                        feature_selection)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m model_regressor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     model_regressor \u001b[39m=\u001b[39m Ridge(alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m                             random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_base.py:134\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[0;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     n_method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhighest_weights\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_selection(data, labels, weights,\n\u001b[1;32m    135\u001b[0m                               num_features, n_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_base.py:80\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[0;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhighest_weights\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     clf \u001b[39m=\u001b[39m Ridge(alpha\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m                 random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m---> 80\u001b[0m     clf\u001b[39m.\u001b[39;49mfit(data, labels, sample_weight\u001b[39m=\u001b[39;49mweights)\n\u001b[1;32m     82\u001b[0m     coef \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mcoef_\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39missparse(data):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1122\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[39m\"\"\"Fit Ridge regression model.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \n\u001b[1;32m   1104\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m _accept_sparse \u001b[39m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[39m.\u001b[39missparse(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver)\n\u001b[0;32m-> 1122\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1123\u001b[0m     X,\n\u001b[1;32m   1124\u001b[0m     y,\n\u001b[1;32m   1125\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m_accept_sparse,\n\u001b[1;32m   1126\u001b[0m     dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1127\u001b[0m     multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1128\u001b[0m     y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1129\u001b[0m )\n\u001b[1;32m   1130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5000, 1]"
     ]
    }
   ],
   "source": [
    "instance_index = 1\n",
    "exp = lime_explainer.explain_instance(\n",
    "    data_row = df.values[instance_index], \n",
    "    predict_fn =  lambda x: np.array([nn_model.predict(x), 1 - nn_model.predict(x)]).reshape(1, -1), \n",
    "    top_labels=2\n",
    "   )\n",
    "\n",
    "exp.show_in_notebook(\n",
    "    show_predicted_value=True,\n",
    "    show_table=True,\n",
    "    show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9facf8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04027544, 0.95972455]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.values[instance_index]\n",
    "np.array([nn_model.predict(x), 1 - nn_model.predict(x)]).reshape(1, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
