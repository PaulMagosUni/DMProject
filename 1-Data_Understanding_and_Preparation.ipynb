{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "\n",
    "import math\n",
    "import utils\n",
    "import shutil as shl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shl.unpack_archive(\"dataset/users.zip\", \"dataset\") # unpacks the users.zip into the datasets folder (The users zip is small enough to be commited to github if we would like)\n",
    "#shl.unpack_archive(\"dataset/tweets.zip\", \"dataset\") # unpacks the tweets.zip into the datasets folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_df = pd.read_csv(\"dataset/tweets_small.csv\")\n",
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\", usecols=[\"id\", \"user_id\"])\n",
    "#tweets_df = pd.read_csv(\"dataset/tweets.csv\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "\n",
    "users_df = pd.read_csv(\"dataset/users.csv\")\n",
    "#users_df.reset_index()\n",
    "#users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "As you can see from comparing the table above and the function results below, we already have noticed that some values are not as expected. For example all the attributes below are states as objects, but we expect many of them to be numbers. This suggests that we will have to prepare and clean the data thouroghly before they can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing and fixing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the created_at coloumn is recognized by pandas as an object, and not as a datetime as we would expect from this attribute. We check the values for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to handle null values in statuses count? does it make sense to use mean/medien in a power law distribution? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean created_at field, by converting string to datetime and checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing string to datetime obj\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])\n",
    "\n",
    "# checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)\n",
    "twitter_first_tweet_datetime = datetime(2006,3,21,12,50,0)\n",
    "#string_to_datetime = lambda string: datetime.strptime(string, expected_format)\n",
    "published_after_twitter_first_tweet = lambda x: x > twitter_first_tweet_datetime\n",
    "all(map(published_after_twitter_first_tweet, users_df[\"created_at\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see the unique number of ids and the actual number of ids..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_ids = len(pd.unique(users_df[\"id\"]))\n",
    "num_ids = len(users_df[\"id\"])\n",
    "print(f\"number of unique IDs: {num_unique_ids} and number of IDs: {num_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could do a similar operation for the names, but people with the same name is not an error. For names it is more interesting to know how many values are missing in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_isnan(a):\n",
    "    return a != a\n",
    "\n",
    "def my_isempty(a):\n",
    "    if a == \"\":\n",
    "        return True\n",
    "\n",
    "\n",
    "number_of_total_names = len(users_df[\"name\"])\n",
    "not_empty_or_missing_names = []\n",
    "empty_or_missing_names = []\n",
    "names_with_only_spaces = []\n",
    "\n",
    "# iterate over all names looking for errors\n",
    "for value in users_df[\"name\"]:\n",
    "    if my_isnan(value) or my_isempty(value): # name is nan or is_empty string\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        empty_or_missing_names.append(value)\n",
    "    if str(value).strip() == \"\":\n",
    "            names_with_only_spaces.append(value)\n",
    "            #users_df[\"name\"].drop(index=value)\n",
    "    elif not(my_isnan(value) or my_isempty(value)):\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        not_empty_or_missing_names.append(value)\n",
    "print(f\" Number of total names = {number_of_total_names} vs total name values that are not NA or empty = {len(not_empty_or_missing_names)}\")\n",
    "\n",
    "\"\"\"\n",
    "for value in users_df[\"name\"]:\n",
    "    if my_isnan(value) or my_isempty(value):\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        empty_or_missing_names.append(value)\n",
    "        #users_df[\"name\"].drop(index=value)\n",
    "    #else:\n",
    "    #    not_empty_or_missing_names.append(value)\n",
    "\"\"\"\n",
    "print(f\" Number of total names = {number_of_total_names} vs total name values that are NA or empty = {len(empty_or_missing_names)}\")\n",
    "\n",
    "#print(len(names_with_only_spaces))\n",
    "#print(empty_or_missing_names)\n",
    "#print(not_empty_or_missing_names)\n",
    "#array_of_nan = np.isnan(users_df[\"name\"])\n",
    "\n",
    "#users_df[\"name\"][1012]\n",
    "#users_df[\"name\"][0]\n",
    "#empty_or_missing_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lang\" field is composed of [IETF language codes](https://en.wikipedia.org/wiki/IETF_language_tag). By selecting only the unique values it's possible to see that there are some erroneous values (e.g. \"Select Language...\", \"xx-lc\"); also, there are some values that are not properly correct (e.g. \"zh-cn\" instead of \"zh-CN\").\n",
    "\n",
    "Since wrong values are just the 0.02% of the number of rows they are just dropped, while the other values are mapped to the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_fields = [\"Select Language...\", \"xx-lc\"] # only 3 elements\n",
    "to_map_fields = {\n",
    "    \"en-gb\": \"en-GB\",\n",
    "    \"zh-tw\": \"zh-TW\",\n",
    "    \"zh-cn\": \"zh-CN\",\n",
    "    \"fil\": \"fil-PH\"\n",
    "}\n",
    "\n",
    "# dropping wrong fields\n",
    "wrong_index = lambda x: True if x[1] in wrong_fields else False\n",
    "wrong_indexes = [index for (index, _) in filter(wrong_index, enumerate(users_df[\"lang\"]))]\n",
    "users_df.drop(index=wrong_indexes, inplace=True)\n",
    "\n",
    "# mapping incorrect values to fixed ones\n",
    "for language in to_map_fields:\n",
    "    indexes = users_df[users_df[\"lang\"] == language].index\n",
    "    for index in indexes:\n",
    "        old_language = users_df.loc[index,\"lang\"]\n",
    "        users_df.loc[index,\"lang\"] = to_map_fields[old_language]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bot: should be yes or no; maybe there are wrong values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"bot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"created at\" should be a time; check if there are type error or if time value is strange (e.g. tweet made before twitter release, which was march 21 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if all the datetime strings are in the valid format (YY-mm-dd H:M:S)\n",
    "#expected_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "#is_datetime_format_correct = lambda x: utils.is_datetime_format_correct(x, expected_format)\n",
    "#all(map(is_datetime_format_correct, users_df[\"created_at\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"]))\n",
    ")\n",
    "\n",
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    by=\"bot\", \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"])) #FIX THIS: USES ALL THE SAMPLES, NOT JUST THE BOTS AND THE USERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.unique(users_df[\"lang\"]) \n",
    "bot_freqs = []\n",
    "user_freqs = []\n",
    "for lang in langs:\n",
    "    user_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 0\")))\n",
    "    bot_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 1\")))\n",
    "\n",
    "langs = pd.unique(users_df[\"lang\"])\n",
    "langs_df = pd.DataFrame({\"lang\": langs, \"bot_freqs\": bot_freqs, \"user_freqs\": user_freqs})\n",
    "langs_df.plot.bar(x=\"lang\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.isnull().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the tweets with user_id in user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = users_df[\"id\"].values\n",
    "user_ids.dtype\n",
    "parsed_user_ids = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "parsed_user_ids.dtype\n",
    "tweets_df[parsed_user_ids.isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by first removing nan values (just 2), then tring to cast to int and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.dropna(subset=[\"id\"], inplace=True)\n",
    "\n",
    "# removing not numeric strings\n",
    "#pd.to_numeric(tweets_df[\"id\"])\n",
    "\n",
    "#tweets_df[\"id\"].isin(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the method above we observe that all our atributes except for \"created_at\" have one or more elements with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wrong_ids = []\n",
    "for (i,k) in enumerate(df[\"id\"]):\n",
    "    if not isinstance(k, str) or not k.isnumeric():\n",
    "        wrong_ids.append(i)\n",
    "print(len(wrong_ids)/len(df[\"id\"]))\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we use sturgen rule for number of bins?\n",
    "\n",
    "# give error: ValueError: hist method requires numerical or datetime columns, nothing to plot.\n",
    "#tweets_df.hist(column=[\"reply_count\",\"retweet_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables trasformations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a6880a325705b3665dbce163bf5d53d724caa231254ade3e201df315622a4af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
