{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"dataset/users.csv\")\n",
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In users.csv there are the following variables:\n",
    "1. User Id: a unique identifier of the user\n",
    "2. Statues Count: According to the teacher, this is the count of the tweets made by the user at the moment of data\n",
    "crawling. According to [Twitter API docs](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user), this is the number of Tweets (including retweets) issued by the user, but not replies (according to Francesca Naretto); since tweets.csv inclues also users' replies note that **there is no link between the number of tweets for each user in tweets.csv and statuses_count**.\n",
    "3. Lang: the userâ€™s language selected\n",
    "4. Created at: the timestamp in which the profile was created\n",
    "5. Label: a binary variable that indicates if a user is a bot or a genuine user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute type and quality\n",
    "\n",
    "In the **user** dataset there are 6 columns:\n",
    "\n",
    "1. The id **column** seems to be ok, all values are integer and there are not null values, we have to check possible duplicates\n",
    " \n",
    "2. We have 1 null value in the **name** column, we also assume that the name could be a string, a number or a special character, the names are not necessarily unique, but maybe it's intresting to check the frequency distribution.\n",
    "\n",
    "3. In the **lang** column we don't have null values, but we have to check whether there are problems in the pattern used to express the language, we expect a categorical attribute \n",
    "\n",
    "4. The **bot** column is numerical as expected (binary), we have to check whether all the numbers are 0 or 1\n",
    "\n",
    "5. The attribute **created_at** has no null values, but we have to check the correctness of the date, both sintactic and semantic (not too far in the past or in the future)\n",
    "\n",
    "6. The **status_count** column has 399 of null values, in the non-null values there would semm to be unexpected float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the uniqueness of ids: all the ids are unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total IDs:\", len(users_df[\"id\"]))\n",
    "print(\"Number of unique IDs:\", len(pd.unique(users_df[\"id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before one name is null. There are also duplicate names, but this isn't a surprising behaviour and by plotting the names' frequencies we can see that there aren't strange phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total names:\", len(users_df[\"name\"]))\n",
    "print(\"Number of unique names:\", len(pd.unique(users_df[\"name\"])))\n",
    "\n",
    "freq = {}\n",
    "for n in users_df['name']:\n",
    "    if n in freq:\n",
    "        freq[n] += 1\n",
    "    else:\n",
    "        freq[n] = 1\n",
    "\n",
    "number_of_total_names = len(users_df[\"name\"])\n",
    "not_empty_or_missing_names = []\n",
    "empty_or_missing_names = []\n",
    "names_with_only_spaces = []\n",
    "\n",
    "# iterate over all names looking for errors\n",
    "for value in users_df[\"name\"]:\n",
    "    if pd.isna(value) or value == \"\": # name is nan or is_empty string\n",
    "        empty_or_missing_names.append(value)\n",
    "    if str(value).strip() == \"\":\n",
    "            names_with_only_spaces.append(value)\n",
    "    elif not(pd.isna(value) or value == \"\"):\n",
    "        not_empty_or_missing_names.append(value)\n",
    "        \n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are not NA or empty = {len(not_empty_or_missing_names)}\")\n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are NA or empty = {len(empty_or_missing_names)}\")\n",
    "\n",
    "pd.DataFrame({\"frequencies\": [_ for _ in freq.values()]}).hist(\n",
    "    column=[\"frequencies\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(freq.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the lang column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"lang\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lang\" field is composed of [IETF language codes](https://en.wikipedia.org/wiki/IETF_language_tag). By selecting only the unique values it's possible to see that there are some erroneous values:\n",
    "* \"Select Language...\" and \"xx-lc\" seems to be **default values**\n",
    "* other values are not properly correct (e.g. \"zh-cn\" instead of \"zh-CN\")\n",
    "We propose to check the most common language used by these 'erroneous values' users and provide them with a more fitting language attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.repair_lang_attribute(users_df)\n",
    "pd.unique(users_df[\"lang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since wrong values are just the 0.02% of the number of rows they are just dropped, while the other values are mapped to the correct ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot attribute is perfectly as expected, all non-null binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"bot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the created_at coloumn is recognized by pandas as an object, and not as a datetime as we would expect from this attribute. Clean created_at field, by converting string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing string to datetime obj\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the statuses count to be an integer, but pandas has interpreted it as a float. This is probably due to the presence of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.statuses_count = users_df.statuses_count.apply(pd.to_numeric, errors=\"coerce\").astype({\"statuses_count\": \"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"]))\n",
    ")\n",
    "\n",
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    by=\"bot\", \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"])) #FIX THIS: USES ALL THE SAMPLES, NOT JUST THE BOTS AND THE USERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.unique(users_df[\"lang\"]) \n",
    "bot_freqs = []\n",
    "user_freqs = []\n",
    "for lang in langs:\n",
    "    user_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 0\")))\n",
    "    bot_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 1\")))\n",
    "langs_df = pd.DataFrame({\"lang\": langs, \"bot_freqs\": bot_freqs, \"user_freqs\": user_freqs})\n",
    "langs_df.plot.bar(x=\"lang\", logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tweets.csv each row contains information about a single tweet. In this case the variables\n",
    "are:\n",
    "1. ID: a unique identifier for the tweet\n",
    "2. User Id: a unique identifier for the user who wrote the tweet\n",
    "3. Retweet count: number of retweets for the tweet in analysis\n",
    "4. Reply count: number of reply for the tweet in analysis\n",
    "5. Favorite count: number of favorites (likes) received by the tweet\n",
    "6. Num hashtags: number of hashtags used in the tweet\n",
    "7. Num urls: number of urls in the tweet\n",
    "8. Num mentions: number of mentions in the tweet\n",
    "9. Created at: when the tweet was created\n",
    "10. Text: the text of the tweet\n",
    "\n",
    "Regarding the num * fields, we don't have to check the validity of the values and can assume they are correct, except for the null and clear incorrect values. In order to substitute the null values of these fields we can exploit the information of the text (however for the mentions and urls it is impossible to check their validity because we may have a mention to a user that does not exist and we cannot know it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") \n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the tweets with user_id in user dataset\n",
    "\n",
    "**THIS METHOD ISN'T FINISHED: THERE ARE STILL SOME STRINGS IN THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_tweets_id_with_invalid_user(tweets_df): # READ ABOVE: THIS METHOD ISN'T COMPLETE\n",
    "    tmp = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "    ids_are_not_in_users_df = tmp[tmp.isin(users_df[\"id\"]) == False]\n",
    "    return ids_are_not_in_users_df\n",
    "\n",
    "invalid_users = get_tweets_id_with_invalid_user(tweets_df)\n",
    "\n",
    "tweets_df.drop(invalid_users.index, inplace=True)\n",
    "\"\"\"\n",
    "tweets_df[\"user_id\"] = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by casting to int and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"id\"] = pd.to_numeric(tweets_df[\"id\"], errors=\"coerce\") # cast field to int and set invalid values to NaN\n",
    "# how to handle duplicates? If there are two different tweets with the same id, how to treat them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "tweets_df[columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first osservation that can be made is that \\*_count and num_\\* fields should contain only positive integers. \n",
    "The second one, by looking on the table above, is that there are some very strange values like inf or 7e+211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Number of invalid values for the following columns:\")\n",
    "for column_name in columns:\n",
    "    # casting all the columns to numeric (and setting invalid value to null)\n",
    "    tweets_df[column_name] = pd.to_numeric(tweets_df[column_name], errors=\"coerce\")\n",
    "    print(f\"{column_name}\")\n",
    "    # evaluating the presence of negative values\n",
    "    print(f\"\\tnegative: {tweets_df[tweets_df[column_name] < 0].size}\")\n",
    "    # evaluating the presence of inf values\n",
    "    print(f\"\\tinf: {utils.get_inf_elements(tweets_df[column_name]).size}\")\n",
    "    # evaluating the presence of decimal values\n",
    "    is_float = lambda n: (not pd.isna(n)) and (not math.isinf(n)) and (not n.is_integer())\n",
    "    decimal_values_series =  tweets_df[column_name].apply(is_float)\n",
    "    print(f\"\\tdecimals: {tweets_df[column_name][decimal_series].size}\")\n",
    "      \n",
    "tweets_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created_all should be datetime\n",
    "\n",
    "Checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df[\"created_at\"] = pd.to_datetime(tweets_df[\"created_at\"], errors=\"coerce\")\n",
    "\n",
    "# finding tweets created before twitter first tweet\n",
    "before_time_tweets_df = tweets_df[tweets_df[\"created_at\"] < datetime(2006,3,21,12,50,0)]\n",
    "before_time_tweets_df.info()\n",
    "\n",
    "# finding tweets created after dataset release\n",
    "before_time_tweets_df = tweets_df[tweets_df[\"created_at\"] > datetime(2022,9,29,11,0,0)]\n",
    "before_time_tweets_df.info()\n",
    "\n",
    "# what to do with these tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") \n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "# REPLACING INF TO NAN; THIS IS JUST A TEMPORARY FUNCTION I PUT HERE IN ORDER TO PLOT THE HISTOGRAMS - Gianluca\n",
    "tweets_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "####\n",
    "tweets_df.hist(\n",
    "    column=columns, \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(tweets_df.size)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables trasformations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
