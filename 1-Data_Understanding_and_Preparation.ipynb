{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"dataset/users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11505 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              11505 non-null  int64         \n",
      " 1   name            11504 non-null  object        \n",
      " 2   lang            11505 non-null  object        \n",
      " 3   bot             11505 non-null  int64         \n",
      " 4   created_at      11505 non-null  datetime64[ns]\n",
      " 5   statuses_count  11106 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(2)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute type and quality\n",
    "\n",
    "In the **user** dataset there are 6 columns:\n",
    "\n",
    "1. The id **column** seems to be ok, all values are integer and there are not null values, we have to check possible duplicates\n",
    " \n",
    "2. We have 1 null value in the **name** column, we also assume that the name could be a strin, a numer or a special character, the names are not necessary unique, but maybe is intresting to check the frequency distribution.\n",
    "\n",
    "3. In the **lang** column we don't have null values, but we have to check whether there are problems in the pattern used to express the language, we expect a categorical attribute \n",
    "\n",
    "4. The **bot** column is numerical as expected (binary), we have to check whether all the numbers are 0 or 1\n",
    "\n",
    "5. The attribute **created_at** has no null values, but we have to check the correctness of the date, both sintactic and semantic (not too far in the past or in the future)\n",
    "\n",
    "6. The **status_count** column has 399 of null values, in the non-null values there would semm to be unexpected float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the uniqueness of ids and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total IDs: 11508\n",
      "Number of unique IDs: 11508\n",
      "Number of total names: 11508\n",
      "Number of unique names: 11361\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total IDs:\", len(users_df[\"id\"]))\n",
    "print(\"Number of unique IDs:\", len(pd.unique(users_df[\"id\"])))\n",
    "print(\"Number of total names:\", len(users_df[\"name\"]))\n",
    "print(\"Number of unique names:\", len(pd.unique(users_df[\"name\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ids are unique!\n",
    "\n",
    "As said before one name is null. \n",
    "\n",
    "It will be interesting to check if the duplicates names are often the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the lang column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'it', 'fr', 'ru', 'es', 'tr', 'en-gb', 'pt', 'nl', 'id',\n",
       "       'zh-tw', 'ja', 'de', 'ko', 'en-AU', 'da', 'ar', 'en-GB',\n",
       "       'Select Language...', 'zh-TW', 'zh-cn', 'pl', 'el', 'fil', 'sv',\n",
       "       'xx-lc'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(users_df[\"lang\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lang\" field is composed of [IETF language codes](https://en.wikipedia.org/wiki/IETF_language_tag). By selecting only the unique values it's possible to see that there are some erroneous values:\n",
    "* \"Select Language...\" and \"xx-lc\" seems to be **default values**\n",
    "* other values are not properly correct (e.g. \"zh-cn\" instead of \"zh-CN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'it', 'fr', 'ru', 'es', 'tr', 'en-GB', 'pt', 'nl', 'id',\n",
       "       'zh-TW', 'ja', 'de', 'ko', 'en-AU', 'da', 'ar', 'zh-CN', 'pl',\n",
       "       'el', 'fil-PH', 'sv'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.repair_lang_attribute(users_df)\n",
    "pd.unique(users_df[\"lang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot attribute is perfectly as expected, all non-null binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(users_df[\"bot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the created_at coloumn is recognized by pandas as an object, and not as a datetime as we would expect from this attribute. Clean created_at field, by converting string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing string to datetime obj\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the end of the data understanding and cleaning of the users database\n",
    "\n",
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)\n",
    "twitter_first_tweet_datetime = datetime(2006,3,21,12,50,0)\n",
    "#string_to_datetime = lambda string: datetime.strptime(string, expected_format)\n",
    "published_after_twitter_first_tweet = lambda x: x > twitter_first_tweet_datetime\n",
    "all(map(published_after_twitter_first_tweet, users_df[\"created_at\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could do a similar operation for the names, but people with the same name is not an error. For names it is more interesting to know how many values are missing in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_isnan(a):\n",
    "    return a != a\n",
    "\n",
    "def my_isempty(a):\n",
    "    if a == \"\":\n",
    "        return True\n",
    "\n",
    "\n",
    "number_of_total_names = len(users_df[\"name\"])\n",
    "not_empty_or_missing_names = []\n",
    "empty_or_missing_names = []\n",
    "names_with_only_spaces = []\n",
    "\n",
    "# iterate over all names looking for errors\n",
    "for value in users_df[\"name\"]:\n",
    "    if my_isnan(value) or my_isempty(value): # name is nan or is_empty string\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        empty_or_missing_names.append(value)\n",
    "    if str(value).strip() == \"\":\n",
    "            names_with_only_spaces.append(value)\n",
    "            #users_df[\"name\"].drop(index=value)\n",
    "    elif not(my_isnan(value) or my_isempty(value)):\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        not_empty_or_missing_names.append(value)\n",
    "print(f\" Number of total names = {number_of_total_names} vs total name values that are not NA or empty = {len(not_empty_or_missing_names)}\")\n",
    "\n",
    "\"\"\"\n",
    "for value in users_df[\"name\"]:\n",
    "    if my_isnan(value) or my_isempty(value):\n",
    "        #print(users_df[\"name\"])\n",
    "        #print(users_df[\"name\"].index(value))\n",
    "        empty_or_missing_names.append(value)\n",
    "        #users_df[\"name\"].drop(index=value)\n",
    "    #else:\n",
    "    #    not_empty_or_missing_names.append(value)\n",
    "\"\"\"\n",
    "print(f\" Number of total names = {number_of_total_names} vs total name values that are NA or empty = {len(empty_or_missing_names)}\")\n",
    "\n",
    "#print(len(names_with_only_spaces))\n",
    "#print(empty_or_missing_names)\n",
    "#print(not_empty_or_missing_names)\n",
    "#array_of_nan = np.isnan(users_df[\"name\"])\n",
    "\n",
    "#users_df[\"name\"][1012]\n",
    "#users_df[\"name\"][0]\n",
    "#empty_or_missing_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since wrong values are just the 0.02% of the number of rows they are just dropped, while the other values are mapped to the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.repair_lang_attribute(users_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bot: should be yes or no; maybe there are wrong values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"created at\" should be a time; check if there are type error or if time value is strange (e.g. tweet made before twitter release, which was march 21 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if all the datetime strings are in the valid format (YY-mm-dd H:M:S)\n",
    "#expected_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "#is_datetime_format_correct = lambda x: utils.is_datetime_format_correct(x, expected_format)\n",
    "#all(map(is_datetime_format_correct, users_df[\"created_at\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df = pd.read_csv(\"dataset/tweets.csv\", usecols=[\"id\", \"user_id\"]) # read only this two colums (saving space)\n",
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"]))\n",
    ")\n",
    "\n",
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    by=\"bot\", \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"])) #FIX THIS: USES ALL THE SAMPLES, NOT JUST THE BOTS AND THE USERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.unique(users_df[\"lang\"]) \n",
    "bot_freqs = []\n",
    "user_freqs = []\n",
    "for lang in langs:\n",
    "    user_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 0\")))\n",
    "    bot_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 1\")))\n",
    "langs_df = pd.DataFrame({\"lang\": langs, \"bot_freqs\": bot_freqs, \"user_freqs\": user_freqs})\n",
    "langs_df.plot.bar(x=\"lang\", logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.isnull().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the tweets with user_id in user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = users_df[\"id\"].values\n",
    "user_ids.dtype\n",
    "parsed_user_ids = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "parsed_user_ids.dtype\n",
    "tweets_df[parsed_user_ids.isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by first removing nan values (just 2), then tring to cast to int and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.dropna(subset=[\"id\"], inplace=True)\n",
    "\n",
    "# removing not numeric strings\n",
    "#pd.to_numeric(tweets_df[\"id\"])\n",
    "\n",
    "#tweets_df[\"id\"].isin(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the method above we observe that all our atributes except for \"created_at\" have one or more elements with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wrong_ids = []\n",
    "for (i,k) in enumerate(df[\"id\"]):\n",
    "    if not isinstance(k, str) or not k.isnumeric():\n",
    "        wrong_ids.append(i)\n",
    "print(len(wrong_ids)/len(df[\"id\"]))\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we use sturgen rule for number of bins?\n",
    "\n",
    "# give error: ValueError: hist method requires numerical or datetime columns, nothing to plot.\n",
    "#tweets_df.hist(column=[\"reply_count\",\"retweet_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables trasformations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
