{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"dataset/users.csv\")\n",
    "#tweets_df = pd.read_csv(\"dataset/tweets.csv\", usecols=[\"id\", \"user_id\"]) # read only this two colums (saving space)\n",
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In users.csv there are the following variables:\n",
    "1. User Id: a unique identifier of the user\n",
    "2. Statues Count: According to the teacher, this is the count of the tweets made by the user at the moment of data\n",
    "crawling. According to [Twitter API docs](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user), this is the number of Tweets (including retweets) issued by the user, but not replies (according to Francesca Naretto); since tweets.csv inclues also users' replies note that **there is no link between the number of tweets for each user in tweets.csv and statuses_count**.\n",
    "3. Lang: the userâ€™s language selected\n",
    "4. Created at: the timestamp in which the profile was created\n",
    "5. Label: a binary variable that indicates if a user is a bot or a genuine user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute type and quality\n",
    "\n",
    "In the **user** dataset there are 6 columns:\n",
    "\n",
    "1. The id **column** seems to be ok, all values are integer and there are not null values, we have to check possible duplicates\n",
    " \n",
    "2. We have 1 null value in the **name** column, we also assume that the name could be a string, a number or a special character, the names are not necessarily unique, but maybe it's intresting to check the frequency distribution.\n",
    "\n",
    "3. In the **lang** column we don't have null values, but we have to check whether there are problems in the pattern used to express the language, we expect a categorical attribute \n",
    "\n",
    "4. The **bot** column is numerical as expected (binary), we have to check whether all the numbers are 0 or 1\n",
    "\n",
    "5. The attribute **created_at** has no null values, but we have to check the correctness of the date, both sintactic and semantic (not too far in the past or in the future)\n",
    "\n",
    "6. The **status_count** column has 399 of null values, in the non-null values there would semm to be unexpected float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the uniqueness of ids: all the ids are unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total IDs:\", len(users_df[\"id\"]))\n",
    "print(\"Number of unique IDs:\", len(pd.unique(users_df[\"id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before one name is null. There are also duplicate names, but this isn't a surprising behaviour and by plotting the names' frequencies we can see that there aren't strange phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total names:\", len(users_df[\"name\"]))\n",
    "print(\"Number of unique names:\", len(pd.unique(users_df[\"name\"])))\n",
    "\n",
    "freq = {}\n",
    "for n in users_df['name']:\n",
    "    if n in freq:\n",
    "        freq[n] += 1\n",
    "    else:\n",
    "        freq[n] = 1\n",
    "\n",
    "number_of_total_names = len(users_df[\"name\"])\n",
    "not_empty_or_missing_names = []\n",
    "empty_or_missing_names = []\n",
    "names_with_only_spaces = []\n",
    "\n",
    "# iterate over all names looking for errors\n",
    "for value in users_df[\"name\"]:\n",
    "    if pd.isna(value) or value == \"\": # name is nan or is_empty string\n",
    "        empty_or_missing_names.append(value)\n",
    "    if str(value).strip() == \"\":\n",
    "            names_with_only_spaces.append(value)\n",
    "    elif not(pd.isna(value) or value == \"\"):\n",
    "        not_empty_or_missing_names.append(value)\n",
    "        \n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are not NA or empty = {len(not_empty_or_missing_names)}\")\n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are NA or empty = {len(empty_or_missing_names)}\")\n",
    "\n",
    "pd.DataFrame({\"frequencies\": [_ for _ in freq.values()]}).hist(\n",
    "    column=[\"frequencies\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(freq.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the lang column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"lang\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lang\" field is composed of [IETF language codes](https://en.wikipedia.org/wiki/IETF_language_tag). By selecting only the unique values it's possible to see that there are some erroneous values:\n",
    "* \"Select Language...\" and \"xx-lc\" seems to be **default values**\n",
    "* other values are not properly correct (e.g. \"zh-cn\" instead of \"zh-CN\")\n",
    "We propose to check the most common language used by these 'erroneous values' users and provide them with a more fitting language attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.repair_lang_attribute(users_df)\n",
    "pd.unique(users_df[\"lang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since wrong values are just the 0.02% of the number of rows they are just dropped, while the other values are mapped to the correct ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot attribute is perfectly as expected, all non-null binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"bot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the created_at coloumn is recognized by pandas as an object, and not as a datetime as we would expect from this attribute. Clean created_at field, by converting string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing string to datetime obj\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the statuses count to be an integer, but pandas has interpreted it as a float. This is probably due to the presence of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.statuses_count = users_df.statuses_count.apply(pd.to_numeric, errors=\"coerce\").astype({\"statuses_count\": \"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"]))\n",
    ")\n",
    "\n",
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    by=\"bot\", \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"])) #FIX THIS: USES ALL THE SAMPLES, NOT JUST THE BOTS AND THE USERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.unique(users_df[\"lang\"]) \n",
    "bot_freqs = []\n",
    "user_freqs = []\n",
    "for lang in langs:\n",
    "    user_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 0\")))\n",
    "    bot_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 1\")))\n",
    "langs_df = pd.DataFrame({\"lang\": langs, \"bot_freqs\": bot_freqs, \"user_freqs\": user_freqs})\n",
    "langs_df.plot.bar(x=\"lang\", logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tweets.csv each row contains information about a single tweet. In this case the variables\n",
    "are:\n",
    "1. ID: a unique identifier for the tweet\n",
    "2. User Id: a unique identifier for the user who wrote the tweet\n",
    "3. Retweet count: number of retweets for the tweet in analysis\n",
    "4. Reply count: number of reply for the tweet in analysis\n",
    "5. Favorite count: number of favorites (likes) received by the tweet\n",
    "6. Num hashtags: number of hashtags used in the tweet\n",
    "7. Num urls: number of urls in the tweet\n",
    "8. Num mentions: number of mentions in the tweet\n",
    "9. Created at: when the tweet was created\n",
    "10. Text: the text of the tweet\n",
    "\n",
    "Regarding the num * fields, we don't have to check the validity of the values and can assume they are correct, except for the null and clear incorrect values. In order to substitute the null values of these fields we can exploit the information of the text (however for the mentions and urls it is impossible to check their validity because we may have a mention to a user that does not exist and we cannot know it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count     Dtype \n",
      "---  ------          --------------     ----- \n",
      " 0   id              13664694 non-null  object\n",
      " 1   user_id         13447413 non-null  object\n",
      " 2   retweet_count   13227562 non-null  object\n",
      " 3   reply_count     13016818 non-null  object\n",
      " 4   favorite_count  13017154 non-null  object\n",
      " 5   num_hashtags    12607172 non-null  object\n",
      " 6   num_urls        13016073 non-null  object\n",
      " 7   num_mentions    12810531 non-null  object\n",
      " 8   created_at      13664696 non-null  object\n",
      " 9   text            13126975 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 8.9 GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the tweets with user_id in user dataset\n",
    "\n",
    "**THIS METHOD ISN'T FINISHED: THERE ARE STILL SOME STRINGS IN THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_tweets_id_with_invalid_user(tweets_df): # READ ABOVE: THIS METHOD ISN\\'T COMPLETE\\n    tmp = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\\n    ids_are_not_in_users_df = tmp[tmp.isin(users_df[\"id\"]) == False]\\n    return ids_are_not_in_users_df\\n\\ninvalid_users = get_tweets_id_with_invalid_user(tweets_df)\\n\\ntweets_df.drop(invalid_users.index, inplace=True)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_tweets_id_with_invalid_user(tweets_df): # READ ABOVE: THIS METHOD ISN'T COMPLETE\n",
    "    tmp = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "    ids_are_not_in_users_df = tmp[tmp.isin(users_df[\"id\"]) == False]\n",
    "    return ids_are_not_in_users_df\n",
    "\n",
    "invalid_users = get_tweets_id_with_invalid_user(tweets_df)\n",
    "\n",
    "tweets_df.drop(invalid_users.index, inplace=True)\n",
    "\"\"\"\n",
    "tweets_df[\"user_id\"] = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by casting to int and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   id              float64\n",
      " 1   user_id         float64\n",
      " 2   retweet_count   object \n",
      " 3   reply_count     object \n",
      " 4   favorite_count  object \n",
      " 5   num_hashtags    object \n",
      " 6   num_urls        object \n",
      " 7   num_mentions    object \n",
      " 8   created_at      object \n",
      " 9   text            object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df[\"id\"] = pd.to_numeric(tweets_df[\"id\"], errors=\"coerce\") # cast field to int and set invalid values to NaN\n",
    "# how to handle duplicates? If there are two different tweets with the same id, how to treat them?\n",
    "\n",
    "tweets_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*_count and num_\\* fields should contain only positive integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   id              object \n",
      " 1   user_id         object \n",
      " 2   retweet_count   float64\n",
      " 3   reply_count     float64\n",
      " 4   favorite_count  float64\n",
      " 5   num_hashtags    float64\n",
      " 6   num_urls        float64\n",
      " 7   num_mentions    float64\n",
      " 8   created_at      object \n",
      " 9   text            object \n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "columns = [\"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "for column_name in columns:\n",
    "    tweets_df[column_name] = pd.to_numeric(tweets_df[column_name], errors=\"coerce\")\n",
    "\n",
    "tweets_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created_all should be datetime\n",
    "\n",
    "Checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# checks if all the users were created after the first tweet published on twitter (so we don\\'t have something strange like a user created in 01-01-1990)\\ntwitter_first_tweet_datetime = datetime(2006,3,21,12,50,0)\\n#string_to_datetime = lambda string: datetime.strptime(string, expected_format)\\npublished_after_twitter_first_tweet = lambda x: x > twitter_first_tweet_datetime\\nall(map(published_after_twitter_first_tweet, users_df[\"created_at\"]))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"created_at\"] = pd.to_datetime(tweets_df[\"created_at\"], errors=\"coerce\")\n",
    "\"\"\"\n",
    "# checks if all the users were created after the first tweet published on twitter (so we don't have something strange like a user created in 01-01-1990)\n",
    "twitter_first_tweet_datetime = datetime(2006,3,21,12,50,0)\n",
    "#string_to_datetime = lambda string: datetime.strptime(string, expected_format)\n",
    "published_after_twitter_first_tweet = lambda x: x > twitter_first_tweet_datetime\n",
    "all(map(published_after_twitter_first_tweet, users_df[\"created_at\"]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   id              object        \n",
      " 1   user_id         object        \n",
      " 2   retweet_count   float64       \n",
      " 3   reply_count     float64       \n",
      " 4   favorite_count  float64       \n",
      " 5   num_hashtags    float64       \n",
      " 6   num_urls        float64       \n",
      " 7   num_mentions    float64       \n",
      " 8   created_at      datetime64[ns]\n",
      " 9   text            object        \n",
      "dtypes: datetime64[ns](1), float64(6), object(3)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we use sturgen rule for number of bins?\n",
    "\n",
    "# give error: ValueError: hist method requires numerical or datetime columns, nothing to plot.\n",
    "#tweets_df.hist(column=[\"reply_count\",\"retweet_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables trasformations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
